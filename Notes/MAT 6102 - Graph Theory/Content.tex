% !TeX root = Graph Theory.tex

\title{\textbf{Graph Theory}}

\date{\today}
\maketitle

\begingroup
\let\clearpage\relax
\tableofcontents
\endgroup

\clearpage

\renewcommand{\nomname}{List of Symbols}
\nomenclature[01]{$V(G)$}{Vertex set of graph $G$}
\nomenclature[02]{$E(G)$}{Edge set of graph $G$}
\nomenclature[03]{$\sim$}{is adjacenct to}
\nomenclature[04]{$\deg(v)$}{Degree of vertex $v$}
\nomenclature[05]{$\ecc(v)$}{Eccentricity of vertex $v$}
\nomenclature[06]{$\rad(G)$}{Radius of graph $G$}
\nomenclature[07]{$\diam(G)$}{Diameter of graph $G$}
\nomenclature[08]{$A(G)$}{Adjacency matrix of graph $G$}
\nomenclature[09]{$B(G)$}{$(0,1)$ Incidence matrix of graph $G$}

\nomenclature[10]{$G - v$}{Graph obtained from $G$ by deleting vertex $v$ and all edges incident with $v$}
\nomenclature[11]{$G - e$}{Graph obtained from $G$ by deleting edge $e$}

\nomenclature[20]{$K_n$}{Complete graph of order $n$ (size $\binom{n}{2}$)}
\nomenclature[21]{$P_n$}{Path graph of order $n$ (size $n - 1$)}
\nomenclature[22]{$C_n$}{Cycle graph of order $n$ (size $n$)}

\nomenclature[30]{$\LG(G)$}{Line graph of $G$}
\printnomenclature[10em]

\clearpage

\section{Introduction}\label{sec:Intro}
A \newterm{graph} is an ordered pair $G = (V, E)$ where $V$ is a nonempty set called the \newterm{vertex set}, whose elements are the \newterm{vertices} of $G$, and $E$ is a set of unordered pairs of distinct vertices of $G$, whose elements are the \newterm{edges} of $G$. The \newterm{order} of $G$ is its number of vertices and the \newterm{size} of $G$ is its number of edges.

Two vertices $u$ and $v$ of $G$ are \newterm{adjacent}, denoted by $u \sim v$, if $uv \in E$ (note that $uv$ here denotes an unordered pair of vertices, and $uv = vu$). If there is no edge between $u$ and $v$, then they are \newterm{nonadjacent}, denoted by $u \nsim v$. The vertex $v$ and the edge $uv$ are said to be \newterm{incident} with each other. The \newterm{degree} of a vertex $v$ is the number of edges incident with it, or equivalently, the number of vertices adjacent with it, and is denoted by $\deg v$. The \newterm{open neighbourhood} (or simply \newterm{neighbourhood}) of a vertex $v$ is the set of all vertices adjacent to $v$, and is denoted by $\Nb(v)$. Thus, $\deg v = |\Nb(v)|$. The \newterm{closed neighbourhood} of $v$ is $\Nb[v] = \Nb(v) \cup \{v\}$.

\begin{Lemma}[Degree-Sum Formula]
The sum of the degrees of all vertices of a graph is twice its size.
\end{Lemma}

\begin{proof}
Let $G$ be a graph, and consider the sum of its degrees, $\sum_{v \in V(G)} \deg v$. As each edge is incident with exactly two vertices, each edge is counted once by two terms in this summation. Thus, the sum is equal to twice the number of edges.
\end{proof}

\begin{Corollary}[Handshaking Lemma]
The number of vertices of odd degree in a graph is always even.
\end{Corollary}

\begin{proof}
Let $G$ be a graph. We know that
\begin{equation}
\sum_{v \in V(G)} \deg v = 2 |E(G)|. \label{eq:deg-sum}
\end{equation}
Considering the vertices of odd and even degrees, we can write \eqref{eq:deg-sum} as
\begin{equation}
\sum_{v \in V(G) ~:~ \deg v\ \text{odd}} \deg v + \sum_{v \in V(G) ~:~ \deg v\ \text{even}} \deg v = 2 |E(G)|.
\end{equation}
Both the RHS and the second term on the LHS are even integers, and therefore so is the first term on the LHS. But a sum of odd integers is even only if the number of terms is even. Thus, $G$ has an even number of vertices of odd degree.
\end{proof}

The \newterm{minimum degree} of $G$ is the $\delta(G) = \min_{v \in V(G)} \deg v$, and the \newterm{maximum degree} of $G$ is $\Delta(G) = \max_{v \in V(G)}$. A \newterm{regular graph} is a graph in which all vertices have the same degree, or equivalently, if $\delta(G) = \Delta(G)$. This common value of the degree is the \newterm{regularity} of the graph. A regular graph of regularity $k$ is a \newterm{$k$-regular} graph. A \newterm{cubic} graph is a $3$-regular graph.

\begin{Exercise}
Prove that if $G$ is a graph of order $n$ and size $m$, then $\delta(G) \le 2\frac m n \le \Delta(G)$.
\end{Exercise}

\begin{Exercise}
Show that if $\Gamma$ is a finite group, then the number of elements of $\Gamma$ that have centralisers of even orders is even.
\end{Exercise}

\begin{Solution*}
Construct a graph $G$ with the vertices of $\Gamma$ as its elements, in which any two vertices $x$ and $y$ are adjacent if $xy = yx$ in $\Gamma$. Then observe that the centraliser $C_\Gamma(x)$ of $x$ in $\Gamma$ is $N[x]$, the closed neighbourhood of $x$ in $G$. Hence, $|C_\Gamma(x)| = \deg_G(x) + 1$, which is even if and only if $\deg_G(x)$ is odd. Now the claimed statement follows from the Handshaking Lemma.
\end{Solution*}

\begin{Theorem}
In any graph on two or more vertices, at least two vertices have the same degree.
\end{Theorem}

\begin{proof}
Let $G$ be a graph of order $n \ge 2$. The minimum possible degree of a vertex of $G$ is $0$, and the maximum possible degree is $n - 1$ (as there are only $n$ vertices in $G$). Thus, in order for the $n$ vertices of $G$ to have different degrees, the $n$ different degrees must be exactly $0, 1, \ldots, n - 1$. But if some vertex of $G$ has degree $n - 1$, then it is adjacent to all other vertices, and therefore $G$ cannot have a vertex of degree $0$. Thus, at least two vertices of $G$ have the same degree.
\end{proof}


\section{Subgraphs and Complements}\label{sec:Subgraphs}

A \newterm{subgraph} of a graph $G$ is a graph $H$ whose vertex and edge sets are, respectively, subsets of the vertex and edge sets of $G$ -- i.e. $V(H) \subseteq V(G)$ and $E(H) \subseteq E(G)$. A \newterm{spanning subgraph} of $G$ is a subgraph containing all the vertices of $G$. A subgraph $H$ of a graph $G$ is an \newterm{induced subgraph} if for all vertices $u, v \in V(H)$, $uv \in E(H)$ whenever $uv \in E(G)$ -- i.e. every edge of $G$ that joins two vertices of $H$ is present in $H$.

\begin{Example}\label{ex:Subgraphs}
\cref{fig:Subgraphs} shows a graph $G$ and three subgraphs $H_1$, $H_2$, and $H_3$ of $G$. The subgraph $H_1$ is neither a spanning subgraph (e.g. it does not contain $v_3$), nor an induced subgraph (e.g. it contains vertices $v_2$ and $v_5$ of $G$ but not the edge $v_2 v_5$). $H_2$ is a spanning subgraph and $H_3$ is an induced subgraph of $G$.
\begin{figure}[!htbp]
\centering
\subcaptionbox{$G$\label{fig:SubgraphsG}}{\includegraphics{Images/Subgraphs-G.pdf}} \hfill
\subcaptionbox{$H_1$\label{fig:SubgraphsH1}}{\includegraphics{Images/Subgraphs-H1.pdf}} \hfill
\subcaptionbox{$H_2$\label{fig:SubgraphsH2}}{\includegraphics{Images/Subgraphs-H2.pdf}} \hfill
\subcaptionbox{$H_3$\label{fig:SubgraphsH3}}{\includegraphics{Images/Subgraphs-H3.pdf}}
\caption{A graph with three of its subgraphs}\label{fig:Subgraphs}
\end{figure}
\end{Example}

A graph is \newterm{complete} if all its vertices are adjacent to one another. The complete graph of order $n$ is denoted by $K_n$. As there is an edge between every pair of distinct vertices of $K_n$, the size of $K_n$ is $\binom n 2$. The \newterm{totally disconnected graph} of order $n$, denoted by $\overline{K_n}$ is the graph of order $n$ that has no edges.

The \newterm{complement} of a graph $G$ is the graph $\overline G$ with the same vertices as $G$, in which any two vertices $u$ and $v$ are adjacent if and only if they are non-adjacent in $G$. Thus, if $G$ is an $(n, m)$-graph, then $\overline G$ is an $\pqty{n, \binom n 2 - m}$-graph. Observe that $\overline K_n$ is (as the notation suggests) the complement of $K_n$.

\begin{Exercise}
If $G$ is a graph of order $n$, and $\deg_G v = k$, what is $\deg_{\overline G} v$?
\end{Exercise}

\begin{Exercise}
Show that if $G$ and $\overline G$ are regular graphs of order $n$ with the same regularity, then the regularity is even and $n = 4t + 1$ for some integer $t$.
\end{Exercise}


\section{Walks, Paths, and Cycles}\label{sec:Walks}

A \newterm{walk} in a simple graph $G$ is a sequence of vertices $v_1, v_2, \ldots, v_k$ such that $v_i \sim v_{i + 1}$ for $i = 1, 2, \ldots, k - 1$ (we will hereafter omit the commas from the sequence). This is a walk \newterm{from $v_1$ to $v_k$} or \newterm{between $v_1$ and $v_k$}, having \newterm{length} $k - 1$. We may also say that this is a walk of length $k - 1$ starting at $v_1$ and ending at $v_k$.

A walk in which no vertex is repeated is a \newterm{path}. Note that the length of a path is the number of edges in it.

A \newterm{closed walk} in $G$ is a walk starting and ending at the same vertex. A closed walk in which no vertex is repeated (except for its first and last vertices being the same) is a \newterm{cycle}. The length of a cycle is also equal to the number of vertices in it. A cycle of the form $v_1 \ldots v_{k-1} v_k$ is usually referred to as ``the cycle $v_1 \ldots v_{k-1}$''.

\begin{Example}\label{ex:Walk}
Consider the graph $G$ shown below.

\begin{center}
\includegraphics{Images/Walks.pdf}
\end{center}
A walk of length $5$ from $b$ to $c$ in $G$ is $b, f, e, a, e, c$.

\begin{center}
\includegraphics{Images/Walk1.pdf}
\end{center}
This walk is not a path, since the vertex $e$ is repeated. An example of a path from $b$ to $c$ in the same graph $G$ is $b, f, e, c$. The length of this path is $3$.

\begin{center}
\includegraphics{Images/Path1.pdf}
\end{center}
A cycle of length $4$ in $G$ is $b, f, e, c, b$.

\begin{center}
\includegraphics{Images/Cycle1.pdf}
\end{center}
\end{Example}

If $P = v_1 \cdots v_k$ is a path from $v_1$ to $v_k$, we define $P[v_i, v_j] = v_i v_{i+1} \cdots v_j$, $1 \le i \le j \le k$, and $P(v_i, v_j) = v_{i+1} v_{i+2} \cdots v_{j-1}$, $1 \le i < j \le k$. If $Q = u_1 \cdots u_l$ is a path from $u_1$ to $u_l$, then we define $PQ = v_1 \cdots v_k u_1 \cdots u_l$. Note that $PQ$ is a walk that may not be a path.

\begin{Theorem}\label{thm:deltaGPath}
If $\delta(G) \ge 2$, then $G$ contains a path of length $\delta(G)$ and a cycle of length greater than $\delta(G)$.
\end{Theorem}

\begin{proof}
Let $P = v_0 v_1 \cdots v_k$ be a longest path in $G$. Then all the neighbours of $v_0$ must be on $P$ (for otherwise, we would get a path longer than $P$). Hence, $k \ge \deg v_0 \ge \delta(G)$.

Next, let $i \le k$ be maximal such that $v_i \sim v_0$. Then $v_0 \cdots v_i v_0$ is a cycle of length $i + 1$, and $i \ge \delta(G)$.
\end{proof}


\section{Distances}\label{sec:Distances}

The \newterm{distance} between two vertices $u$ and $v$ of a graph $G$ is the length of a shortest path between $u$ and $v$ -- such a shortest path between $u$ and $v$ is a \newterm{geodesic} from $u$ to $v$. Thus, the distance between $u$ and $v$ in $G$, denoted by $d_G(u, v)$ is the length of a geodesic from $u$ to $v$ in $G$. When the graph $G$ is clear from the context, we will write $d_G(u, v)$ as $d(u, v)$.

The \newterm{eccentricity} of a vertex $v$, denoted by $\ecc(v)$, is the maximum of all distances from $v$ to any other vertex. That is,
\begin{equation*}
    \ecc(v) = \max_{u \in V(G)} d(u, v) .
\end{equation*}

The \newterm{diameter} of $G$ is the maximum of the eccentricities of vertices of $G$, and the \newterm{radius} of $G$ is the minimum of the eccentricities of vertices of $G$. They are denoted by $\diam(G)$ and $\rad(G)$ respectively. Thus,
\begin{align*}
    \diam(G) & = \max_{v \in V(G)} \ecc(v)= \max_{u, v \in V(G)} d(u, v) \\
    \rad(G) & = \min_{v \in V(G)}\ecc(v) = \min_{v \in V(G)} \max_{u \in V(G)} d(u, v).
\end{align*}

The set of all vertices of $G$ having minimum eccentricity, i.e. the set of all $v \in V(G)$ such that $\ecc v = \rad G$, is the \newterm{centre} of $G$.


\section{Connectedness}\label{sec:Connectedness}

A graph is \newterm{connected} if there is a path between every two of its vertices. Otherwise, it is \newterm{disconnected}. A \newterm{(connected) component} of a graph $G$ is a maximal connected subgraph of $G$. Thus, a graph $G$ is connected if and only if it has exactly one component.

\begin{Theorem}\label{thm:GorGCompConn}
For any graph $G$, either $G$ or $\overline G$ is connected.
\end{Theorem}

\begin{proof}
Consider a graph $G$, and suppose that $G$ is disconnected. We shall show that $\overline G$ is connected, by showing that there is a path between every two vertices of $\overline G$.

Let $u$ and $v$ be any two vertices of $\overline G$. If they are not adjacent in $G$, then they are adjacent in $\overline G$, and hence there is a path $uv$ from $u$ to $v$ in $\overline G$. If $u$ and $v$ are adjacent in $G$, then they belong to the same component of $G$. As $G$ is disconnected, it has at least one more component containing at least one vertex, say $w$, which is necessarily non-adjacent to both $u$ and $v$. Hence, in $\overline G$, $w$ is adjacent to both $u$ and $v$. Thus, there is a path $uwv$ from $u$ to $v$ in $\overline G$. Therefore, $\overline G$ is connected.
\end{proof}

\begin{Theorem}\label{thm:Diam>=3}
For any connected graph $G$, if $\diam G \ge 3$, then $\diam \overline G \le 3$.
\end{Theorem}

\begin{proof}
Consider a graph $G$ of diameter at least $3$. Then there exist vertices $u$ and $v$ in $G$ such that $d_G(u, v) = 3$. This implies that $u$ and $v$ are non-adjacent in $G$, and hence adjacent in $\overline G$.

Now, consider any two vertices $x$ and $y$ other than $u$ and $v$. In $G$, $x$ can be adjacent to at most one of $u$ and $v$, for otherwise, $d_G(u,v) = 2$. Hence, $x$ is adjacent to at least one of $u$ and $v$ in $\overline G$. Similarly, $y$ is adjacent to at least one of $u$ and $v$ in $\overline G$. Thus, there is a path of length at most $3$ from $x$ to $y$ in $\overline G$ (namely $xuy$, $xvy$, $xuvy$, or $xvuy$), which implies that $d_{\overline G}(x, y) \le 3$. Therefore, $\diam \overline G \le 3$.
\end{proof}

\begin{Exercise}
If $G$ is a graph of order $n$ and minimum degree $\delta(G) \ge \frac{n-1}{2}$, show that $G$ is connected and $\diam G \le 2$.
\end{Exercise}


\section{Graph Isomorphism}\label{sec:Isomorphism}

An \newterm{isomorphism} from a graph $G$ to a graph $H$ is a bijective function $f \colon V(G) \to V(H)$ such for all vertices $u$ and $v$ of $G$, $u \sim_G v$ if and only if $f(u) \sim_H f(v)$. In other words, a graph isomorphism is a bijection from the vertex set of the first graph to that of the second, that preserves both edges and non-edges. If there exists an isomorphism from $G$ to $H$, then $G$ and $H$ are \newterm{isomorphic}. Then we write $G \cong H$.

Isomorphic graphs have exactly the same structure -- i.e. all properties of the graph that do not depend on the labelling or drawing will be shared by isomorphic graphs. For example, isomorphic graphs have the same order, size, degree sequence, diameter, and radius. Indeed, if $f$ is an isomorphism from $G$ to $H$, and $v$ is a vertex of $G$, then the neighbours of $f(v)$ in $H$ are the images of the neighbours of $v$ in $G$, and $\deg_G v = \deg_H f(v)$. Similarly, if $u$ and $v$ are two vertices of $G$, then $d_G(u, v) = d_H(f(u), f(v))$.

\begin{Theorem}
Graph isomorphism is an equivalence relation on the class of all graphs.
\end{Theorem}

\begin{proof}
To show that graph isomorphism is an equivalence relation, we need to show that $\cong$ is a reflexive, symmetric, transitive relation between graphs. First, observe that the identity map on the vertex set of a graph is an isomorphism from the graph to itself -- for, if $G$ is a graph and $\id$ denotes the identity map on its vertex set then for any two vertices $u$ and $v$ of $G$, $u \sim v$ if and only if $\id(u) \sim \id(v)$, as $\id(u) = u$ and $\id(v) = v$. Hence, $\cong$ is reflexive.

Next, suppose that $G \cong H$. Then there exists an isomorphism $f$ from $G$ to $H$. Since $f \colon V(G) \to V(H)$ is bijective, it has an inverse $f^{-1} \colon V(H) \to V(G)$. We claim that $f^{-1}$ is an isomorphism from $H$ to $G$. We know that $f^{-1}$ is bijective. To see that it preserves edges and non-edges, observe that if $x$ and $y$ are two vertices of $H$, then $x = f(f^{-1}(x))$ and $y = f(f^{-1}(y))$, which implies that $x \sim_H y$ if and only if $f^{-1}(x) \sim_G f^{-1}(y)$ (since $f$ is an isomorphism from $G$ to $H$). Therefore, $f^{-1}$ is an isomorphism from $H$ to $G$. This shows that $H \cong G$. Thus, $\cong$ is symmetric.

Finally, suppose that $G \cong H$ and $H \cong K$. Then there exist isomorphisms $f$ from $G$ to $H$ and $g$ from $H$ to $K$. We claim that $g \circ f$ is an isomorphism from $G$ to $K$. Indeed, $g \circ f$ is a function from $V(G)$ to $V(K)$, and being a composition of bijections, is itself a bijection. Now, suppose $u$ and $v$ are two vertices of $G$. Then $u \sim_G v$ if and only if $f(u) \sim_H f(v)$ (since $f$ is an isomorphism from $G$ to $H$) if and only if $g(f(u)) \sim_K g(f(v))$ (since $g$ is an isomorphism from $H$ to $K$). Thus, $g \circ f$ is an isomorphism from $G$ to $K$. Therefore, $\cong$ is transitive.
\end{proof}


\section{Self-Complementary Graphs}\label{sec:SC}

A graph is \newterm{self-complementary} if it is isomorphic to its complement -- i.e. $G$ is self-complementary if $G \cong \overline G$. For example, $K_1$, $P_4$ and $C_5$ are self-complementary graphs of orders $1$, $4$, and $5$ respectively. There is one more self-complementary graph of order $5$, namely the \newterm{bull graph}, which can be constructed by adding one new vertex to $P_4$ and making it adjacent to the two non-pendant vertices of the path. This graph is shown below.

\begin{center}
\includegraphics{Images/BullGraph.pdf}
\end{center}

\begin{Theorem}\label{thm:SCOrder}
The order of any self-complementary graph is $4k$ or $4k + 1$, for some non-negative integer $k$.
\end{Theorem}

\begin{proof}
Let $G$ be a self-complementary graph of order $n$ and size $m$. Then the size of $\overline G$ is $\binom n 2 - m$. Since $G \cong \overline G$, $m = \binom n 2 - m$, which implies that $m = \frac 1 2 \binom n 2 = \frac {n(n - 1)}{4}$. As $m$ is an integer, this implies that $4$ divides $n(n - 1)$, which in turn implies that either one of $n$ and $n - 1$ is divisible by $4$, or both $n$ and $n - 1$ are even. Since the latter is not possible, it follows that $n = 4k$ or $n - 1 = 4k$, i.e. $n = 4k$ or $4k + 1$ for some integer $k$.
\end{proof}


From \cref{thm:GorGCompConn}, we know that a graph and its complement cannot both be disconnected. Thus, if $G$ is a disconnected graph, then $\overline G$ must be connected, and therefore it cannot be isomorphic to $G$. This implies that a self-complementary graph is necessarily connected.

\begin{Corollary}\label{cor:SCConn}
Every self-complementary graph is connected. \qed
\end{Corollary}

Similarly, from \cref{thm:Diam>=3}, we obtain the following corollary about the diameter of self-complementary graphs.

\begin{Corollary}
Every non-trivial self-complementary graph has diameter $2$ or $3$.
\end{Corollary}

\begin{proof}
Consider a non-trivial, self-complementary graph $G$, and suppose that it has diameter strictly greater than $3$. Then, by \cref{thm:Diam>=3}, $\diam \overline G \le 3$, which implies that $\diam \overline G \ne \diam G$, a contradiction, since $G \cong \overline G$. Hence, $\diam G \le 3$. On the other hand, a non-trivial graph cannot have diameter $0$, hence $\diam G \ge 1$. But if $\diam G = 1$, then $G$ is a non-trivial complete graph, whose complement is a totally disconnected graph, which is again impossible. Hence, $\diam G = 2$ or $3$.
\end{proof}

\begin{Exercise}
If $G$ is a regular self-complementary graph of order $n$, show that $n = 4k + 1$, for some integer $k$, and $\diam G = 2$.
\end{Exercise}

\begin{Exercise}
Let $G$ be a self-complementary graph, and let $H$ be the graph obtained by taking the disjoint union of $H$ and $P_4$, and making every vertex of $H$ adjacent to the two non-pendant vertices of this $P_4$. Then show that $H$ is also self-complementary. What is the graph $H$ obtained in this manner if $G = K_1$?
\end{Exercise}

\begin{Exercise}
Construct a self-complementary graph of order $9$.
\end{Exercise}

\begin{Exercise}
Show that for each positive integer $n$ of the form $4k$ or $4k + 1$, where $k$ is an integer, there exists at least one self-complementary graph of order $n$.
\end{Exercise}


\section{Bipartite Graphs}\label{sec:Bipartite}

A graph $G = (V, E)$ is \newterm{bipartite} if its vertex set $V$ can be partitioned into two subsets $V_1$ and $V_2$ such that no two vertices in $V_i$ are adjacent, for $i = 1, 2$. That is, there exist two non-empty, disjoint subsets $V_1, V_2 \subseteq V$ such that $V_1 \cup V_2 = V$, and every edge of $G$ (if any) joins a vertex in $V_1$ with a vertex in $V_2$. Then we say that $(V_1, V_2)$ is a \newterm{bipartition} of $G$.

The following theorem characterises bipartite graphs in terms of its cycles. A cycle is \newterm{even} if its length is even and \newterm{odd} if its length is odd.

\begin{Theorem}
A graph is bipartite if and only if it contains no odd cycles.
\end{Theorem}

\begin{proof}
First, suppose that $G$ is a bipartite graph with bipartition $(V_1, V_2)$, and let $v_1 v_2 \ldots v_k$ be a cycle of length $k$ in $G$. Without loss of generality, suppose that $v_1 \in V_1$. Then, since $v_2 \sim v_1$, $v_2 \in V_2$, which in turn implies that $v_3 \in V_1$, as $v_2 \sim v_3$. Proceeding similarly, we see $v_i \in V_1$ if $i$ is odd and $v_i \in V_2$ if $i$ is even. But $v_k \sim v_1$ and $v_1 \in V_1$ implies that $v_k \in V_2$. Therefore, $k$ (the length of the cycle) is even.

Conversely, suppose $G$ is a graph that has no odd cycles. Without loss of generality, assume that $G$ is connected -- otherwise, apply the argument to each component. Let $v$ be any vertex of $G$. Define subsets $V_1$ and $V_2$ of $V(G)$ as follows:
\begin{align*}
    V_1 = \qty{\, u \in V \mid d(u, v)\ \text{is even} \,} \\
    V_2 = \qty{\, u \in V \mid d(u, v)\ \text{is odd} \,}.
\end{align*}
We claim that $(V_1, V_2)$ is a bipartition of $G$.

Suppose not, and let $x$ and $y$ be adjacent vertices of $G$, both belonging to $V_i$ for $i = 1$ or $2$. Let $P$ and $Q$ be shortest paths from $v$ to $x$ and $y$ respectively. Let $w$ be the last vertex common to both $P$ and $Q$ when traversing $P$ from $v$ to $x$. Then the path $P[w,x]$, the edge $(x, y)$, and the path $Q[y,w]$ form an odd cycle in $G$, which is a contradiction. Hence, $(V_1, V_2)$ is a bipartition of $G$ as claimed.
\end{proof}

A \newterm{complete bipartite graph} is a bipartite graph in which every vertex of one partite set is adjacent to all the vertices of the other partite set. The complete bipartite graph with partite sets of cardinalities $p$ and $q$ is denoted by $K_{p,q}$.

\begin{Exercise}
If $G$ is a bipartite graph with bipartition $(V_1, V_2)$, show that
\begin{equation*}
\sum_{v \in V_1} \deg v = \sum_{v \in V_2} \deg v.
\end{equation*}
\end{Exercise}


\section{Trees}\label{sec:Trees}

A \newterm{tree} is a connected, acyclic graph. There are several well known characterisations or alternative definitions of trees. We take the given definition as the basic one and prove its equivalence to some others.

\begin{Theorem}\label{thm:UniPath}
A graph $T$ is a tree if and only if there is a unique path joining every two vertices of $T$.
\end{Theorem}
\begin{proof}
First, suppose that $T$ is a tree, and let $u$ and $v$ be vertices of $T$. Since $T$ is connected, there is a path, say $P$, joining $u$ and $v$. Now we must show that this path is unique. Assume to the contrary that there exists another path $Q$ from $u$ to $v$. When traversing $P$ from $u$ to $v$, let $x$ be the first vertex common to $P$ and $Q$ such that its successor on $P$ is not present on $Q$. Let $y$ be the next vertex common to both $P$ and $Q$ when traversing $P$ from $x$ to $v$. Then $P[x,y]$ and $Q[x,y]$ together form a cycle in the tree $T$, which is a contradiction. Thus, $P$ is the unique path joining $u$ and $v$.

Conversely, suppose that $T$ is a graph in which there is a unique path joining any two vertices. Clearly, $T$ is connected. To show that $T$ is acyclic, suppose that $v_1 v_2 \ldots v_n$ is a cycle in $T$. Then we get two different paths joining $v_1$ and $v_n$, namely the path $v_1 v_2 \ldots v_n$ and the path $v_1 v_n$ (since $v_1 \sim v_n$ in the cycle). This contradicts our assumption. Thus, $T$ must be acyclic and hence is a tree.
\end{proof}

The next two results show that the size of a tree is always one less than its order, and that conversely, this property together with either connectedness or acyclicity implies that the graph is a tree.
\begin{Theorem}\label{thm:Conn;p=q+1}
A $(p, q)$-graph $T$ is a tree if and only if it is connected and $p = q + 1$.
\end{Theorem}
\begin{proof}
Let $T$ be a tree with $p$ vertices and $q$ edges. Then $T$ is connected. We prove that $p = q + 1$ by induction. This is clearly true when $p = 1$. Assume it to be true for all trees of order less than $p$. Now in $T$, we know that every two vertices are joined by a unique path. Thus, if $e$ is any edge of $T$, then the graph $T - \{e\}$ obtained by deleting $e$ has exactly two components, say $T_1$ and $T_2$. Each one is a tree, since it is connected and acyclic. Let $T_i$ have $p_i$ vertices and $q_i$ edges, $i = 1, 2$. Then by the hypothesis, $p_i = q_i + 1$ (since $p_i < p$). But $p = p_1 + p_2$ and $q = q_1 + q_2 + 1$ (since the size of $T - \{e\}$ is one less than that of $T$). Thus, $p = q_1 + q_2 + 2 = q + 1$.

For the converse, suppose that $T$ is a connected $(p,q)$-graph with $p = q + 1$. We must show that is acyclic. Suppose to the contrary that $T$ has a cycle $C$ with $k$ vertices. Then $C$ has $k$ edges as well. Since $T$ is connected, there is a path from every vertex not on $C$ to some vertex of $C$. The shortest path from each vertex $v$ not on $C$ to a vertex on $C$ has a unique edge incident with $v$, which is not part of $C$. Since there are $p - k$ vertices in $T$ not on $C$, there are $p - k$ such edges. Thus $q \ge (p - k) + k = p$, which contradicts our assumption that $p = q + 1$. Thus, $T$ must be acyclic.
\end{proof}

In the following theorem, the proof of the direct part is identical to that of Theorem~\ref{thm:Conn;p=q+1}, except for the assertion being about acyclicity rather than connectedness. The proof of the converse part is entirely different.
\begin{Theorem}\label{thm:Acyc;p=q+1}
A $(p,q)$-graph $T$ is a tree if and only if it is acyclic and $p = q + 1$.
\end{Theorem}
\begin{proof}
Let $T$ be a tree with $p$ vertices and $q$ edges. Then $T$ is acyclic. We prove that $p = q + 1$ by induction. This is clearly true when $p = 1$. Assume it to be true for all trees of order less than $p$. Now in $T$, we know that every two vertices are joined by a unique path. Thus, if $e$ is any edge of $T$, then the graph $T - \{e\}$ obtained by deleting $e$ has exactly two components, say $T_1$ and $T_2$. Each one is a tree, since it is connected and acyclic. Let $T_i$ have $p_i$ vertices and $q_i$ edges, $i = 1, 2$. Then by the hypothesis, $p_i = q_i + 1$ (since $p_i < p$). But $p = p_1 + p_2$ and $q = q_1 + q_2 + 1$ (since the size of $T - \{e\}$ is one less than that of $T$). Thus, $p = q_1 + q_2 + 2 = q + 1$.

Conversely, suppose that $T$ is an acyclic $(p,q)$-graph with $p = q + 1$. To show that $T$ is connected, we need to prove that it is connected -- i.e. it has only one component. Let $T$ have $k$ components $T_1, \ldots, T_k$. Each one is acyclic, and being connected, is a tree. Thus from the first part of the theorem, we know that if $p_i$ and $q_i$ are respectively the order and size of the component $T_i$, $p_i = q_i + 1$. Now $p = p_1 + \cdots p_k = (q_1 + 1) + \cdots (q_k + 1) = q + k$. But we know that $p = q + 1$. Therefore, $k = 1$. Thus, $T$ is a tree.
\end{proof}

\begin{Exercise}
A \newterm{pendant vertex} of a graph is a vertex of degree $1$. Prove that every non-trivial tree contains at least two pendant vertices.\\
    \hint{Observe that a non-trivial tree cannot have a vertex of degree zero. Use Handshaking Lemma and assume every degree is at least $2$ to get a contradiction.}
\end{Exercise}

\begin{Exercise}
The \newterm{centre} of a graph $G$ is the set of all vertices of $G$ with minimum eccentricity -- i.e. the set of all vertices $v$ of $G$ with $\ecc v = \rad v$. Show that every tree has a centre consisting of either exactly one vertex or exactly two adjacent vertices.\\
\hint{Observe that deleting all pendant vertices of a tree results in a new tree with the same centre.}
\end{Exercise}

\begin{Solution*}
Let $T$ be a tree on $n$ vertices. We prove the result by induction on $n$.

If $n = 1$ or $2$, the result obviously holds. Suppose, for the sake of induction, that the result holds for all trees of order less than $n$.

Consider $T$, of order $n \ge 3$. Then $T$ has at least two pendant vertices. Let $T'$ be the tree (of order less than $n$) obtained by deleting all the pendant vertices of $T$.

Then the vertices of $T'$ have eccentricities exactly one less than their eccentricities in $T$, and therefore, $T$ and $T'$ have the same centre. Hence, the result follows by induction.
\end{Solution*}


\section{Cartesian Product of Graphs}\label{sec:CartProds}

The \newterm{Cartesian product} of two graphs $G$ and $H$ is the graph denoted by $G \times H$, whose vertex set is $V(G) \times V(H)$, in which two vertices $(u_1, v_1)$ and $(u_2, v_2)$ are adjacent if and only if either $u_1 = u_2$ and $v_1 \sim v_2$ or $u_1 \sim u_2$ and $v_1 = v_2$.

\begin{Exercise}
	Prove that if $G$ is a graph of order $p_1$ and size $q_1$, and $H$ is a graph of order $p_2$ and size $q_2$, then $G \times H$ is a graph of order $p_1 p_2$ and size $p_1 q_2 + p_2 q_1$.
\end{Exercise}

\begin{Solution*}
	By definition, the vertex set of $G \times H$ is the Cartesian product $V(G) \times V(H)$ of the vertex sets of $G$ and $H$, and therefore contains $|V(G)| \times |V(H)|$ elements. Thus, the order of $G \times H$ is $p_1 p_2$.
	
	Now, consider any vertex $(u, v)$ of $G \times H$. Corresponding to every vertex $u'$ adjacent to $u$ in $G$, there is an edge from $(u, v)$ to $(u', v))$ in $G \times H$. Similarly, corresponding to every vertex $v'$ adjacent to $v$ in $H$, there is an edge from $(u, v)$ from $(u, v')$ in $G \times H$. Thus, the degree of $(u, v)$ in $G \times H$ is $\deg u + \deg v$. Hence, by the Handshaking Lemma, the size of $G \times H$ is half the sum of its vertex degrees, which is
	\begin{align*}
		\frac 1 2 \sum_{u \in V(G), v \in V(H)} (\deg u + \deg v) & = \frac 1 2 \sum_{u \in V(G), v \in V(H)} \deg u + \frac 1 2 \sum_{u \in V(G), v \in V(H)} \deg v \\
		& = p_2 \pqty{\frac 1 2 \sum_{u \in V(G)} \deg u} + p_1 \pqty{\frac 1 2 \sum_{v \in V(H)} \deg v} \\
		& = p_2 q_1 + p_1 q_2.
	\end{align*}
\end{Solution*}

\begin{Exercise}
	Show that if $G$ is an $r$-regular graph and $H$ is an $s$-regular graph, then $G \times H$ is a regular graph of regularity $r + s$.
\end{Exercise}


\section{Adjacency Matrices}\label{sec:AdjMat}

The \newterm{adjacency matrix} of a graph $G$ of order $n$, with vertex set $V = \{v_1, \ldots, v_n\}$, is the $n \times n$ matrix $A = A(G)$ whose $(i,j)$-entry is
\begin{equation*}
a_{ij} = \begin{cases}
1, & v_i \sim v_j \\
0, & v_i \nsim v_j.
\end{cases}
\end{equation*}

\begin{Example}\label{ex:GNM(6-11)AdjMat}
The adjacency matrix of the graph
\begin{center}
\includegraphics{Images/GNM(6,11).pdf}
\end{center}
is
\begin{equation*}
A = \begin{bmatrix}
0 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 1 & 0 & 1 & 1 & 1 & 1 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0
\end{bmatrix}.
\end{equation*}
\end{Example}

Observe that, as the graphs we discuss are simple graphs and therefore have no self-loops on vertices, no vertex is adjacent to itself -- i.e. $a_{ii} = 0$ for all $i = 1, \ldots, n$. Also, since the graphs are undirected, $v_i \sim v_j$ if and only if $v_j \sim v_i$ -- i.e. $a_{ij} = a_{ji}$. Thus, we have the following observation.

\begin{Observation}
The adjacency matrix of a (simple, undirected) graph is a symmetric, zero-diagonal, $(0, 1)$-matrix.
\end{Observation}

In the $i$\nth row of the adjacency matrix, for each $j$, the $j$\nth entry is $1$ if $v_j$ is adjacent to $v_i$, and $0$ otherwise. That is, the number of $1$s in the $i$\nth row is the number of vertices adjacent to $v_i$, or in other words, the degree of $v_i$. Thus, the row sums of $A$ are the vertex degrees. Observe that $A \mathbbm 1$ is the vector of row sums, where $\mathbbm 1$ is the vector (of suitable size) with all entries equal to $1$. For instance, with the matrix $A$ given in \cref{ex:GNM(6-11)AdjMat},
\begin{equation*}
A = \begin{bmatrix}
0 & 1 & 1 & 1 & 1 & 1 & 1 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 1 & 0 & 1 & 1 & 1 & 1 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1
\end{bmatrix} =
\begin{bmatrix}
6 \\ 2 \\ 6 \\ 2 \\ 2 \\ 2 \\ 2
\end{bmatrix}.
\end{equation*}
From the Handshaking Lemma and the preceding observation, it follows that the sum of all entries of $A$ is twice the number of edges of the graph.

\begin{Exercise}\label{exer:A2ij}
Show that the $(i,j)$-entry of $A^2$ is the number of walks of length $2$ from $v_i$ to $v_j$. Hence show that $\trace(A^2) = 2|E(G)|$.\\
\hint{Recall that if $A$ is any $n \times n$ matrix, then the $(i,j)$-entry of $A^2$ is $\sum_{k=1}^{n} a_{ik}a_{kj}$. As $A$ is a $(0, 1)$-matrix, each term in this summation is $1$ or $0$, with the former if and only if $a_{ik} = a_{kj} = 1$. What does this imply about the vertices $v_i$, $v_k$, and $v_j$? Then, as $k$ varies from $1$ to $n$, what does the value of the sum imply about $v_i$ and $v_j$?}
\end{Exercise}

The following result (which generalises the statement in \cref{exer:A2ij}) shows that the adjacency matrix can be used to obtain certain information about walks in the graph.

\begin{Theorem}
Let $A$ be the adjacency matrix of a graph $G$ with vertex set $\{v_1, \ldots, v_n\}$. Then the $(i,j)$-entry of $A^m$, for any positive integer $m$, is the number of walks of length $m$ from $v_i$ to $v_j$.
\end{Theorem}

\begin{proof}
We prove the result by induction on $m$. For $m = 1$, the $(i,j)$-entry of $A^1 = A$ is $a_{ij}$, which is $1$ if and only if $v_i$ is adjacent to $v_j$, i.e. if and only if there is a walk of length $1$ (namely, an edge) from $v_i$ to $v_j$. Thus, the result holds for $m = 1$.

Now suppose, for the sake of induction, that the result holds for some $m \ge 1$, and consider $A^{m + 1}$. The $(i,j)$-entry of $A^{m + 1}$ is
\begin{equation*}
(A^{m + 1})_{ij} = \sum_{k = 1}^{n} (A^m)_{ik} a_{kj}.
\end{equation*}
First, note that $a_{kj} = 1$ if and only if $v_k \sim v_j$. Therefore, the above sum is equal to the sum of all $(A^m)_{ik}$ where $v_k \sim v_j$. Now, by the induction hypothesis, $(A^m)_{ik}$ is the number of walks of length $m$ from $v_i$ to $v_k$. If $v_j$ is adjacent to $v_j$, then each walk of length $m$ from $v_i$ to $v_k$, together with the edge from $v_j$ to $v_j$, forms a walk of length $m + 1$ from $v_i$ to $v_j$. Thus, for each $k$ such that $v_k \sim v_j$, $(A^m)_{ik} a_{kj} = (A^m)_{ik}$ is the number of walks of length $m + 1$ from $v_i$ to $v_j$ that pass through $k$. Summing over all $k$, this gives the total number of walks of length $m + 1$ from $v_i$ to $v_j$. Hence the result follows by induction.
\end{proof}

\begin{Theorem}
Let $A$ be the adjacency matrix of a graph $G$ with vertex set $\{v_1, \ldots, v_n\}$. Then
\begin{enumerate}[label=(\roman*)]
\item $\tr(A^2) = 2 |E(G)|$
\item $\tr(A^3) = 6 c_3(G)$
\end{enumerate}
where $c_3(G)$ denotes the number of triangles in $G$.
\end{Theorem}

\begin{proof}
We know that $(A^m)_{ij}$ is the number of walks of length $m$ from $v_i$ to $v_j$.
\begin{enumerate}[label=(\roman*)]
\item Hence, the $i$\nth diagonal entry of $A^2$, viz. $(A^2)_{ii}$, is the number of walks of length $2$ from $v_i$ to itself. Any walk of length $2$ from $v_i$ to itself is of the form $v_i v_j v_i$, where $v_j$ is a vertex adjacent to $v_i$. Thus, the number of such walks is equal to the number of vertices adjacent to $v_i$, i.e. $\deg v_i$. Hence, $\tr(A^2) = \sum_{i=1}^n \deg v_i = 2|E(G)|$, by Handshaking Lemma.

\item Similarly, $(A^3)_{ii}$ is the number of walks of length $3$ from $v_i$ to itself. Any such walk is of the form $v_i v_j v_k v_i$, which implies that $v_i$, $v_j$, and $v_k$ form a triangle in $G$. Moreover, each such triangle corresponds to two distinct walks from $v_i$ to itself, when traversed in the two opposite directions. Thus, $(A^3)_{ii}$ is twice the number of triangles having $v_i$ as one of its vertices. Therefore, $\tr(A^3)$ is $6 c_3(G)$, since each triangle contains three vertices, each of which counts the triangle twice in the sum $\tr(A^3)$. \qedhere
\end{enumerate}
\end{proof}

\begin{Exercise}
With notation as above, prove that the $i$\nth diagonal entry of $A^4$ is
\begin{equation*}
	(A^4)_{ii} = 2c_4(v_i) + \sum_{j \colon v_j \sim v_i} \deg v_j + 2 \binom{\deg v_i}{2}
\end{equation*}
where $c_4(v_i)$ denotes the number of cycles of length $4$ containing the vertex $v_i$, and hence show that the total number of cycles of length $4$ in $G$ is
\begin{align*}
	c_4(G) & = \frac 1 8 \tr A^4 - \frac 1 4 \sum_{i=1}^{n} (\deg v_i)^2 + \frac{|E(G)|}{4} \\
	& = \frac 1 8 \tr A^4 - \frac 1 4 \sum_{uv \in E(G)} \pqty{\deg u + \deg v - 1} \\
	& = \frac 1 8 \tr A^4 - \frac {|E(G)|} 4 - \frac 1 2 \sum_{i=1}^n \binom {\deg v_i} 2.
\end{align*}
\end{Exercise}


\section{Incidence Matrices}\label{sec:IncMat}

Consider an $(n, m)$-graph $G$ having vertex set $\{v_1, \ldots, v_n\}$ and edge set $\{e_1, \ldots, e_m\}$. The \newterm{incidence matrix} of $G$ is the $n \times m$ matrix $B = B(G)$ whose $(i, j)$-entry is $1$ if the vertex $v_i$ is incident with the edge $e_i$, and $0$ otherwise.

\begin{Example}\label{ex:GNM(6-8)AdjMat}
The incidence matrix of the graph
\begin{center}
\includegraphics{Images/GNM(6,8).pdf}
\end{center}
is
\begin{equation*}
B = \begin{bmatrix}
1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 & 1 & 0 & 1 \\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 \\
\end{bmatrix}.
\end{equation*}
\end{Example}

Each column of the incidence matrix corresponds to an edge of the graph, and the only non-zero entries in the column correspond to the end-vertices of the edge -- thus, each column contains exactly two $1$s. In a simple graph, there is at most one edge between a given pair of vertices, and hence no two columns of the incidence matrix can be equal. We therefore have the following observation.

\begin{Observation}
The incidence matrix of a (simple, undirected) graph is a $(0, 1)$-matrix in which every column has exactly two $1$s, and no two columns are equal.
\end{Observation}


\section{Line Graphs}\label{sec:LineGraphs}

Let $G$ be a graph with at least one edge. The \newterm{line graph} of $G$ is the graph $\LG(G)$ whose vertex set is the edge set of $G$, in which two vertices $e$ and $f$ are adjacent if and only if the edges $e$ and $f$ of $G$ are adjacent.

\begin{Example}\label{ex:LineGrpahs}
\cref{fig:LineGraphs} shows a graph $G$ with eight edges and and its line graph $\LG(G)$.
\begin{figure}[!htbp]
	\centering
	\subcaptionbox{$G$}{\includegraphics{Images/GNM(7,8).pdf}} \hspace{5em}
	\subcaptionbox{$\LG(G)$}{\includegraphics{Images/L(GNM(7,8)).pdf}}
	\caption{A graph and its line graph}\label{fig:LineGraphs}
\end{figure}
\end{Example}

If $u$ and $v$ are edges joined by an edge $e$ in $G$, then in $\LG(G)$, the vertex $e$ will be adjacent to all the vertices corresponding to the edges of $G$ other than $e$ that are incident with $u$ and $v$ (see \cref{fig:L(G)Neighbourhood}). Thus, $\deg_{\LG(G)} e = \deg_G u + \deg_G v - 2$.
\begin{figure}[!htbp]
\centering
\includegraphics{Images/L(G)Neighbourhood.pdf}
\caption{Neighbourhood of a vertex in $\LG(G)$}
\label{fig:L(G)Neighbourhood}
\end{figure}

\begin{Theorem}
For any graph $G$ of size $m \ge 1$, its line graph $\LG(G)$ has order $m$ and size $\displaystyle\sum_{v \in V(G)} \binom{\deg_G v}{2}$.
\end{Theorem}

\begin{proof}
By definition, the vertices of $\LG(G)$ are the edges of $G$, and hence the order of $\LG(G)$ is the size of $G$, $m$.

Now, let $e = uv$ be an edge of $G$. In $\LG(G)$, $e$ is a vertex, and it is adjacent to another vertex $f$ if and only if $f$ is an edge of $G$ and is adjacent to $e$, i.e. $f$ is an edge of $G$ incident with one of the end vertices of $e$, namely $u$ and $v$. Thus, the degree of the vertex $e$ of $\LG(G)$ is equal to the total number of edges that are incident with either $u$ or $v$ in $G$, except for the edge $e$ itself.

Clearly, $u$ is incident with to $\deg_G u - 1$ edges other than $e$, and $v$ is incident with $\deg_G v - 1$ edges other than $e$. Thus, the degree of $e$ in $\LG(G)$ is $\deg_G u  - 1 + \deg_G v - 1$.

By Handshaking Lemma, the size of $\LG(G)$ is half the sum of its vertex degrees, which is
\begin{equation*}
	\frac 1 2 \sum_{uv \in E(G)} (\deg_G u - 1 + \deg_G v - 1).
\end{equation*}
As the summation is over the edges of $G$, each vertex $v$ of $G$ appears exactly $\deg v$ times in the above summation, which can therefore be written as
\begin{equation*}
	\pushQED{\qed}
	\frac 1 2 \sum_{v \in V(G)} (\deg_G v)(\deg_G v - 1) = \sum_{v \in V(G)} \binom{\deg_G v}{2}.\qedhere
\end{equation*}
\end{proof}

The adjacency matrix of the line graph of $G$ can be computed from the incidence matrix of $G$, as shown in the following result.

\begin{Theorem}
	If $B$ is the incidence matrix of a graph $G$, then the adjacency matrix of its line graph $\LG(G)$ is
	\begin{equation*}
		A\pqty{\LG(G)} = B^T B - 2I
	\end{equation*}
	where $I$ is the identity matrix of order $|E(G)|$.
\end{Theorem}

\begin{proof}
	Let $G$ be an $(n, m)$-graph with edge set $E = \{e_1, \ldots, e_m\}$. The incidence matrix $B = B(G)$ is of order $n \times m$, and therefore $B^T B - 2I$ is of order $m \times m$.
	
	Observe that the $(i, j)$ entry of $B^T B$ is the dot product of the $i$\nth and $j$\nth columns of $B$. As each column of $B$ has exactly two non-zero entries, both equal to $1$, the $(i, i)$ entry of $B^T B$ is $2$, and therefore the diagonal entries of $B^T B - 2I$ are all zero.
	
	For $i \ne j$, the dot product of the $i$\nth and $j$\nth columns of $B$ will be $1$ if the edges $e_i$ and $e_j$ are adjacent (i.e. have one vertex in common), and $0$ otherwise -- note that the dot product cannot be $2$, as no two distinct columns of $B$ can be equal. Thus, for $i \ne j$, the $(i, j)$-entry of $B^T B$, which is equal to the $(i, j)$ entry of $B^T B - 2I$, is $1$ if and only if the edges $e_i$ and $e_j$ are adjacent in $G$, or equivalently, the vertices $e_i$ and $e_j$ of $\LG(G)$ are adjacent. Thus, $B^T B - 2I$ is the adjacency matrix of $G$.
\end{proof}

A graph $G$ is said to be a line graph if it is the line graph of some graph $H$. Not every graph is a line graph, as shown by the following example.

\begin{Example}
Consider the graph $G = K_{1, 3}$, the star graph of order $4$. Suppose $G$ is the line graph of some graph $H$. Then $H$ has four edges, say $e_1, e_2, e_3, e_4$, which are the four vertices of $G$. Suppose $e_1$ is the central vertex of $G$. Then, as the vertices $e_2$ and $e_3$ are adjacent to $e_1$ in $G$, the edge $e_1$ of $H$ has one end-vertex in common with each of $e_2$ and $e_3$. Let $u$ be the vertex of $e_1$ common with $e_2$ and $v$ the vertex of $e_1$ common with $e_3$. Note that $u \ne v$, since $e_2$ and $e_3$ are not adjacent in $G$. Now, since $e_4$ is adjacent to $e_1$ in $G$, the edge $e_4$ of $H$ has either $u$ or $v$ as an end-vertex. Then $e_4$ is adjacent to either $e_2$ or $e_3$ in $G$, which is not possible.
\end{Example}


\section{Blocks and Cutvertices}\label{sec:Blocks}

A vertex $v$ of a graph $G$ is a \newterm{cutvertex} if $G - v$ has more components than $G$. A connected graph is \newterm{nonseparable} or \newterm{$2$-connected} if it has no cutvertices. A maximal nonseparable subgraph of a graph $G$ is a \newterm{block} of $G$. A nonseparable is itself also called a block.

\begin{Theorem}\label{thm:CutverChar}
If $G$ is a connected graph, and $v$ is any vertex of $G$, then the following are equivalent:
\begin{enumerate}[label=(\roman*)]
\item\label{it:CutverChar1} $v$ is a cutvertex of $G$.
\item\label{it:CutverChar2} There exist vertices $u$ and $w$ of $G$, distinct from $v$, such that every $u$-$w$ path passes through $v$.
\item\label{it:CutverChar3} There exists a partition of $V(G) - \{v\}$ into two non-empty subsets $U$ and $W$ such that for all $u \in U$ and $w \in W$, every $u$-$w$ path passes through $v$.
\end{enumerate}
\end{Theorem}

\begin{proof}
\cref{it:CutverChar1} $\implies $ \cref{it:CutverChar3}. Since $v$ is a cutvertex, the graph $G - v$ is disconnected, i.e. it has two or more components. Let $U$ be the set of all the vertices in any one of the components, and let $W$ be the set of all the remaining vertices of $G - v$. Clearly, $\{U, W\}$ is a partition of $V(G) - \{v\}$. Now, if $u \in U$ and $w \in W$, then $u$ and $w$ are in different components of $G - v$, which implies that any path from $u$ to $w$ must pass through $v$.

\noindent \cref{it:CutverChar3} $\implies$ \cref{it:CutverChar2} is obvious as the latter is a special case of the former.

\noindent \cref{it:CutverChar2} $\implies$ \cref{it:CutverChar1}. Consider the graph $G - v$. As every $u$-$w$ path passes through $v$, none of them is present in $G - v$, and therefore $G - v$ is disconnected. Hence, $v$ is a cutvertex of $G$.
\end{proof}

A \newterm{cutedge} or \newterm{bridge} of a graph $G$ is an edge $e$ of $G$ such that $G - e$ has more components than $G$. The following characterisation of bridges can be proved along similar lines to that of \cref{thm:CutverChar}.

\begin{Theorem}\label{thm:BridgeChar}
If $G$ is a connected graph, and $e$ is any edge of $G$, then the following are equivalent:
\begin{enumerate}[label=(\roman*)]
\item\label{it:BridgeChar1} $e$ is a bridge of $G$.
\item \label{it:BridgeChar2} $e$ is not on any cycle of $G$.
\item\label{it:BridgeChar3} There exist vertices $u$ and $w$ of $G$ such that every $u$-$w$ path contains $e$.
\item\label{it:BridgeChar4} There exists a partition of $V(G)$ into two non-empty subsets $U$ and $W$ such that for all $u \in U$ and $w \in W$, every $u$-$w$ path contains $e$. \qed
\end{enumerate}
\end{Theorem}

\begin{Theorem}\label{thm:BlockChar}
If $G$ is a connected graph of order at least $3$, then the following are equivalent:
\begin{enumerate}[label=(\roman*)]
\item\label{it:BlockChar1} $G$ is a block.
\item \label{it:BlockChar2} Every two vertices of $G$ lie on a common cycle.
\item\label{it:BlockChar3} Every vertex and edge of $G$ lie on a common cycle.
\item\label{it:BlockChar4} Every two edges of $G$ lie on a common cycle. \qed
\end{enumerate}
\end{Theorem}


\section{Connectivity}\label{sec:Connectivity}

A set $S$ of vertices of a connected graph $G$ is a \newterm{separating set} or \newterm{vertex cut} of $G$ if $G - S$ is disconnected or trivial (i.e. a graph of order $1$). The \newterm{vertex connectivity} (or \newterm{connectivity}) of $G$, denoted by $\kappa(G)$ (or $\kappa$) is the cardinality of a minimum separating set of $G$ -- i.e. the minimum number of vertices $G$ whose removal results in a disconnected or trivial graph. Similarly, a \newterm{disconnecting set} of a connected graph $G$ is a set $S$ of edges of $G$ such that $G - S$ is disconnected or trivial. The cardinality of a minimum disconnecting set of $G$ is the \newterm{edge connectivity} of $G$, and is denoted by $\lambda(G)$ (or $\lambda$). The vertex connectivity and edge connectivity of a disconnected graph are defined to be $0$.

\begin{Theorem}\label{thm:ConnectivityBounds}
For any graph $G$, $\kappa(G) \le \lambda(G) \le \delta(G)$.
\end{Theorem}

\begin{proof}
If $\delta(G) = 0$, then clearly, $\lambda(G) = 0$. If $\delta(G) \ge 1$, then disconnecting all the edges incident with a vertex of degree $\delta(G)$ disconnects $G$, and hence $\lambda(G) \le \delta(G)$.

If $G$ is disconnected, then $\kappa(G) = \lambda(G) = 0$. If $\lambda(G) = 1$, then $G$ has a bridge, say $e$, and hence the removal of any one end-vertex of $e$ results in a disconnected graph or $K_1$, hence $\kappa(G) = 1$.

Next, suppose that $G$ has $\lambda \ge 2$ edges whose removal disconnects it. Then the removal of $\lambda - 1$ of these edges results in a graph with a bridge $e = uv$. Each of these edges has at least one end-vertex distinct from $u$ and $v$. From each edge, remove one such vertex. Then the edges are removed as well, and the resulting graph is either disconnected, in which case $\kappa < \lambda$, or else has $uv$ as a bridge. Then, removal of $u$ or $v$ gives a disconnected or trivial graph. Hence, $\kappa \le \lambda$.
\end{proof}

\begin{Theorem}
For all integers $a$, $b$, $c$, with $0 \le a \le b \le c$, there exists a graph $G$ with $\kappa(G) = a$, $\lambda(G) = b$, and $\delta(G) = c$. \qed
\end{Theorem}

It is easy to see that $\kappa(K_n) = n -1$ and $\kappa(K_{p,q}) = \min(p, q)$. The following theorem gives the connectivity of the hypercube.

\begin{Theorem}
For any $k \ge 0$, the connectivity of the hypercube $Q_k$ is $\kappa(Q_k) = k$.
\end{Theorem}

\begin{proof}
As $Q_k$ is $k$-regular, $\kappa(Q_k) \le k$. We claim that every vertex cut of $Q_k$ contains at least $k$ vertices. We prove this claim by induction on $k$. For $k = 0$ or $1$, it is obvious.

Suppose the claim holds for $Q_{k - 1}$, and consider $G = Q_k$, $k \ge 2$. Recall that $Q_k \cong K_2 \times Q_{k - 1}$. Thus $G$ has two subgraphs $G_1$ and $G_2$, each isomorphic to $Q_{k - 1}$, joined by a perfect matching $M$ of $G$. Now, let $S$ be any vertex cut of $G$. If both $G_1 - S$ and $G_2 - S$ are connected, then $G - S$ is also connected, unless $S$ contains at least one end-vertex of every edge of the matching $M$. Then, $|S| \ge |M| = 2^{k - 1} \ge k$, as $k \ge 2$.

Next, suppose that $G_1 - S$ is disconnected. Then $|S \cup V(G_1)| \ge k - 1 = \kappa(Q_{k - 1})$ (by the induction hypothesis). If $S$ contains no vertex of $G_2$, then, as $G_2$ is connected, and every vertex of $G_1 - S$ has a neighbour in $G_2$, $G - S$ is connected, which is a contradiction. Thus, $S$ contains at least one vertex of $G_2$. Hence, $|S| \ge (k - 1) + 1 = k$, as required.
\end{proof}

\begin{Corollary}
For any $k \ge 0$, the edge connectivity of the hypercube $Q_k$ is $\lambda(Q_k) = k$.
\end{Corollary}

\begin{proof}
From \cref{thm:ConnectivityBounds}, $k = \kappa(Q_k) \le \lambda(Q_k) \le \delta(Q_k) = k$.
\end{proof}

\begin{Theorem}
If $G$ is $3$-regular, then $\kappa(G) = \lambda(G)$.
\end{Theorem}

\begin{proof}
Let $S$ be a minimum vertex cut of $G$. We know that $\lambda(G) \ge \kappa(G) = |S|$. We will show that $\lambda(G) = \kappa(G)$ by constructing a disconnecting set of size $\kappa(G) = |S|$.


Let $H_1$ and $H_2$ be two components of $G - S$. Since $S$ is a minimum vertex cut, every vertex in $S$ has a neighbour in $H_1$ and a neighbour in $H_2$. For each vertex $v$ of $S$ that has no neighbour inside $S$, delete the edge from $v$ to that subgraph $H_1$ or $H_2$ in which it has a unique neighbour. For each vertex $u$ of $S$ that has a neighbour in $S$, delete the edge from $u$ to $H_1$. Then the resulting graph is disconnected, and hence $\lambda(G) = |S| = \kappa(G)$.
\end{proof}


\section{Covering and Independence}\label{sec:CoveringIndependence}

A vertex $v$ and an edge $e$ of a graph $G$ \newterm{cover} each other if $v$ is incident on $e$. A \newterm{vertex cover} is a set of vertices of that cover all the edges. An \newterm{edge cover} is a set of edges that cover all vertices.

A vertex (or edge) cover is \newterm{minimal} if no proper subset of itself is a vertex (or edge) cover. It is \newterm{minimum} if it has the least cardinality among all vertex (or edge) covers of the graph. The cardinality of a minimum vertex cover of $G$ is the \newterm{vertex covering number} of $G$, denoted by $\alpha_0(G)$, and the cardinality of a minimum edge cover of $G$ is the \newterm{edge covering number} of $G$, denoted by $\alpha_1(G)$.

A set of vertices or a set of edges of $G$ is \newterm{independent} if no two of its elements are adjacent. An independent set of vertices (or edges) is \newterm{maximal} if it is not properly contained in any independent set, and is \newterm{maximum} if it has the largest cardinality among all independent sets of vertices (or edges). The \newterm{vertex independence number} of $G$, denoted by $\beta_0(G)$, is the cardinality of a maximum independent set of vertices of $G$. The \newterm{edge independence number} of $G$, denoted by $\beta_1(G)$, is the cardinality of a maximum independent set of edges of $G$.

\begin{Example}\label{ex:CoveringIndependence}
The values of the parameters $\alpha_0$, $\beta_0$, $\alpha_1$, and $\beta_1$ for some families of graphs are listed below.
\def\arraystretch{1.4}
\begin{equation*}
\begin{array}{|c|cccc|}
\hline
G		&	\alpha_0			&	\beta_0				&	\alpha_1			&	\beta_1 \\
\hline
K_n		&	n - 1				&	1					&	\ceil{\frac n 2}	&	\floor{\frac n 2} \\
K_{p,q}	&	\min(p, q)			&	\max(p, q)			&	\max(p, q)			&	\min(p, q) \\
C_n		&	\ceil{\frac n 2}	&	\floor{\frac n 2}	&	\floor{\frac n 2}	&	\ceil{\frac n 2} \\
P_n		&	\floor{\frac n 2}	&	\ceil{\frac n 2}	&	\ceil{\frac n 2}	&	\floor{\frac n 2} \\
Q_k		&	2^{k-1} = \frac n 2	&	2^{k-1} = \frac n 2	&	2^{k-1} = \frac n 2	&	2^{k-1} = \frac n 2 \\
\hline
\end{array}
\end{equation*}
\end{Example}

\begin{Exercise}
Justify the values of the parameters given in \cref{ex:CoveringIndependence}.
\end{Exercise}

\begin{Exercise}
Prove that a set $S$ of vertices of $G$ is independent if and only if $V(G) \setminus S$ is a vertex cover of $G$.
\end{Exercise}

\subsection*{Gallai's theorem}
Notice that for each graph $G$ in \cref{ex:CoveringIndependence}, $\alpha_0(G) + \beta_0(G) = \alpha_1(G) + \beta_1(G) = n$, the order of $G$. This is true in general for all graphs, and this fact is known as Gallai's theorem.

\begin{Theorem}[Gallai]
For any graph $G$ of order $n$,
\begin{equation*}
\alpha_0(G) + \beta_0(G) = \alpha_(G) + \beta_1(G) = n.
\end{equation*}
\end{Theorem}

\begin{proof}
Let $M_0$ be a maximum set of independent vertices of $G$. Then $\beta_0 = |M_0|$, and $V \setminus M_0$ is a vertex cover. Hence, $\alpha_0 \le \vqty{V \setminus M_0} = n - \beta_0$. Let $N_0$ be a minimum cover of $G$. Then $\alpha_0 = |N_0|$, and $V \setminus N_0$ is independent. Hence, $\beta_0 \ge \vqty{V \setminus N_0} = n - \alpha_0$. Thus, $\alpha_0 + \beta_0 = n$.

Now, let $M_1$ be a maximum set of independent edges. Form an edge cover $Y$ of $G$ by adding to $M_1$ one edge incident with each vertex not covered by $M_1$. Then $|Y| = n - |M_1| = n - \beta_1$, which implies that $n - \beta_1 \ge \alpha_1$, i.e. $\alpha_1 + \beta_1 \le n$.

Next, let $N_1$ be a minimum edge cover of $G$. Then an independent set of edges is obtained by taking one edge of each component of the induced graph $\langle N_1 \rangle$. Hence, $\beta_1 \ge n - |N_1| = n - \alpha_1$, which implies that $\alpha_1 + \beta_1 \ge n$. Thus, $\alpha_1 + \beta_1 = n$.
\end{proof}


\section{Matching}\label{sec:Matching}

A \newterm{matching} of $G$ is a set of independent edges of $G$. A vertex is \newterm{saturated} by a matching $M$ (it is \newterm{$M$-saturated}) if it is incident to some edge of $M$, and otherwise it is \newterm{unsaturated} by $M$ (it is \newterm{$M$-unsaturated}). A matching is
\begin{enumerate}[label=(\roman*)]
\item \newterm{maximal} if it is not properly contained in any other matching.
\item \newterm{maximum} if it has greatest cardinality among all matchings.
\item \newterm{perfect} if it saturates all vertices.
\end{enumerate}

A path of $G$ is \newterm{$M$-alternating} if its edges are alternately from $M$ and $E(G) \setminus M$. An \newterm{$M$-augmenting} path is an $M$-alternating path whose end-vertices are $M$-unsaturated.

\begin{Note*}
If $P$ is an $M$-augmenting path, we can obtain a matching of cardinality $|M| + 1$ by replacing the edges of $P$ in $M$ by the edges of $P$ not in $M$.
\end{Note*}

Recall that the symmetric difference of two sets $A$ and $B$ is the set $A \symdiff B = (A \setminus B) \cup (B \setminus A)$. If $M$ and $M'$ are two matchings of a graph $G$, then the \newterm{symmetric difference} of $M$ and $M'$ (also denoted $M \symdiff M'$) is the graph induced by the set $M \symdiff M'$.

\begin{Lemma}\label{lem:SymmDiffMatchings}
Every component of the symmetric difference of two matchings is a path or an even cycle.
\end{Lemma}

\begin{proof}
Let $F = M \symdiff M'$. As $M$ and $M'$ are matchings, every vertex has at most one incident edge from each of them. Hence, $\Delta(F) \le 2$. As the edges must be alternately from $M \setminus M'$ and $M' \setminus M$, each cycle is of even length.
\end{proof}

\begin{Theorem}[Berge]
A matching $M$ of $G$ is maximum if and only if $G$ has no $M$-augmenting path.
\end{Theorem}

\begin{proof}
If $G$ has an $M$-augmenting path $P$, then the matching obtained from $M$ by removing the edges of $P$ that are in $M$ and adding those edges of $P$ that are not in $M$ has cardinality $|M| + 1$, which implies that $M$ cannot be a maximum matching. Thus, if $M$ is a maximum matching, $G$ has no $M$-augmenting path.

Conversely, suppose that $M$ is not a maximum matching in $G$. Then $G$ has a matching $M'$, with $|M'| > |M|$. Let $F = M \symdiff M'$. Then, by \cref{lem:SymmDiffMatchings}, every component of $F$ is a path or an even cycle, and each even cycle contains an equal number of edges from $M$ and $M'$. Hence, as $|M'| > |M|$, at least one component of $F$ must be path, which is an $M$-augmenting path of $G$.
\end{proof}

\subsection*{Hall's matching condition}\label{subsec:Hall}
Let $G$ be a bipartite graph with bipartition $(V_1, V_2)$. If $M$ is a matching of $G$ that saturates $V_1$ (i.e. saturates all vertices in $V_1$), then observe that for every subset $S \subseteq V_1$, $|N_G(S)| \ge |S|$, where $N_G(S)$ is the set of all vertices of $G$ that have at least one neighbour in $S$ -- equivalently, it is the union of the neighbourhoods of all the vertices in $S$.

If $G$ is a bipartite graph, then a partite set $X$ of $G$ is said to satisfy \newterm{Hall's condition} if $|N_G(S)| \ge |S|$ for all $S \subseteq X$.

\begin{Theorem}[Hall's Theorem]\label{thm:Hall}
A bipartite graph $G$ with bipartition $(V_1, V_2)$ has a matching that saturates $V_1$ if and only if $V_1$ satisfies Hall's condition.
\end{Theorem}

\begin{proof}
If $G$ has a matching that saturates $V_1$, then distinct vertices $u$ and $v$ in $V_1$ have distinct neighbours via the edges of the matching incident on them. Thus, for any $S \subseteq V_1$, $|N_G(S)| \ge |S|$.

For the converse, suppose that $G$ has a maximum matching $M$ that does not saturate $V_1$. We will show that $V_1$ does not satisfy Hall's condition, by constructing a set $S$ for which $|N_G(S)| < |S|$.

Let $u$ be an $M$-unsaturated vertex in $V_1$. Let $S$ be the vertices in $V_1$ reachable by an $M$-alternating path, and let $T$ be the vertices in $V_2$ reachable by an $M$-alternating path. Note that $u \in S$.

\noindent Claim: $M$ matches $T$ with $S \setminus \{u\}$.

First, observe that any $M$-alternating path from $u$ reaches $V_2$ along edges not in $M$ and returns to $V_1$ along edges in $M$. Thus, each vertex of $S \setminus \{u\}$ is reached by an edge in $M$ from a vertex in $T$. Every vertex in $T$ must be $M$-saturated, for otherwise, $G$ would have an $M$-augmenting path, which is not possible as $M$ is a maximum matching. Therefore, any $M$-alternating path from $u$ to a vertex $y \in T$ can be extended to a vertex in $S$ via some edge of $M$. These edges define a bijection between $T$ and $S \setminus \{u\}$.

Thus, $|T| = |S| - 1$, and $T \subseteq N_G(S)$. We show that $T = N(S)$. Suppose, to the contrary, that some vertex $Y \in V_2 \setminus T$ has a neighbour $x \in S$. The edge $xy$ cannot be in $M$, as $u$ is $M$-unsaturated, and the other vertices in $S$ are matched to $T$ by $M$. Hence, an $M$-alternating path from $u$ to $x$ can be extended to $y$ by the edge $xy$, which contradicts the assumption that $y \notin T$. Therefore, $y$ cannot have such a neighbour $x \in S$.

Now, as $T = N_G(S)$, $|N_G(S)| = |T| = |S| - 1 < |S|$, and hence $V_1$ does not satisfy Hall's condition.
\end{proof}

\begin{Corollary}\label{cor:k-regBipartitePM}
For each positive integer $k$, every $k$-regular bipartite graph has a perfect matching.
\end{Corollary}

\begin{proof}
Let $G$ be a $k$-regular bipartite graph with bipartition $(V_1, V_2)$. Then $|V_1| = |V_2|$. Hence, a maximum matching is a perfect matching if and only if it saturates $V_1$. We show this by proving that $V_1$ satisfies Hall's matching condition.

Consider any $S \subseteq V_1$. Then the induced subgraph $H = \langle S \cup N_G(S) \rangle$ is a bipartite subgraph in which every vertex of $S$ has degree $k$. Hence, $k|S| = \sum_{v \in N_G(S)} \deg_H v \le k|N_G(S)|$, which implies that $|N_G(S)| \ge |S|$. That is, $V_1$ satisfies Hall's condition, as required.
\end{proof}


\section{Graph Colouring}\label{sec:Colouring}

A \newterm{$k$-colouring} of a graph $G$, where $k$ is a non-negative integer, is a function $c \colon V(G) \to S$, where $|S| = k$. The elements of $S$ are \newterm{colours}, and the set of all vertices of $G$ with one colour is a \newterm{colour class}. Henceforth, we will consider $S = \{1, 2, \ldots, k\}$. A $k$-colouring is \newterm{proper} if adjacent vertices receive distinct colours (note that if $c(v) = i$, then we say that the vertex $v$ \newterm{receives} or \newterm{is assigned} the colour $i$). $G$ is \newterm{$k$-colourable} if it has a proper $k$-colouring. The \newterm{chromatic number} of $G$, denoted by $\chi(G)$, is the least $k$ such that $G$ is $k$-colourable. If $\chi(G) = k$, then $G$ is \newterm{$k$-chromatic}, and a $k$-colouring is \newterm{optimal}.

\begin{Exercise}
Prove the following:
\begin{enumerate}
\item $\chi(K_n) = n$.

\item $\chi(C_n) = \begin{cases}
2, & n\ \text{is even} \\
3, & n\ \text{is odd}.
\end{cases}$

\item $\chi(G) = 2$ if and only if $G$ is a bipartite graph with at least one edge.

\item If $H$ is any subgraph of $G$, then $\chi(G) \ge \chi(H)$.
\end{enumerate}
\end{Exercise}

A \newterm{clique} of $G$ is a maximal complete subgraph of $G$. The order of the largest clique of $G$ is the \newterm{clique number} of $G$, denoted by $\omega(G)$.

\begin{Theorem}
For any graph $G$ of order $n$,
\begin{eqnarray}
\max\pqty{ \omega(G),  \frac n {\beta_0(G)} } \le \chi(G) \le \Delta(G) + 1.
\end{eqnarray}
\end{Theorem}

\begin{proof}
Since the clique of order $\omega(G)$ is a subgraph with chromatic number $\omega(G)$, $\chi(G) \ge \omega(G)$. As the colour classes in a proper $\chi(G)$-colouring of $G$ partition $V(G)$ into $\chi(G)$ sets, each of which is independent and hence has at most $\beta_0(G)$ vertices, $n = |V(G)| \le \chi(G) \beta_0(G)$, and hence $\chi(G) \ge \frac n {\beta_0(G)}$.

Now, we prove that $\chi(G) \le \Delta(G) + 1$, by induction on $n$. The claim obviously holds for $n = 1$ ($\Delta(G) = 0$, $\chi(G) = 1$).

Suppose that the result is true for any graph of order $n - 1$, and consider a graph $G$ of order $n$, $n > 1$. Let $v$ be any vertex of $G$. Then $\Delta(G - v) \le \Delta(G)$, and hence, by the induction hypothesis, $G - v$ is $(\Delta(G) + 1)$-colourable. Consider such a colouring. Now, $\deg_G v \le \Delta(G)$, and therefore at least one of the $\Delta(G) + 1$ colours is not assigned to any neighbour of $v$ in the colouring of $G - v$. Assign one such colour to $v$ to extend the colouring of $G - v$ to a proper $(\Delta(G) + 1)$-colouring of $G$.
\end{proof}

\begin{Theorem}
The chromatic number of the Cartesian product of two graphs $G$ and $H$ is $\chi(G \times H) = \max(\chi(G), \chi(H))$.
\end{Theorem}

\begin{proof}
Since $G \times H$ has subgraphs isomorphic to $G$ and $H$, $\chi(G \times H) \ge \max(\chi(G), \chi(H))$.

Let $k = \max(\chi(G), \chi(H))$, and let $c_1$ and $c_2$ be optimal colourings of $G$ and $H$ respectively, with colours $\{1, \ldots, k\}$. Define a colouring $c$ of $G \times H$ by $c(u, v) = c(u) + c(v)$ modulo $k$, for $(u, v) \in V(G \times H)$. Clearly, $c$ is a $k$-colouring of $G \times H$. To see that $c$ is proper, suppose $(u_1, v_1) \sim_{G \times H} (u_2, v_2)$. Then $c(u_1, v_1) - c(u_2, v_2) = \bqty{c(u_1) - c(u_2)} + \bqty{c(v_1) - c(v_2)}$. One of the two bracketed terms is $0$ and the other is non-zero modulo $k$.
\end{proof}

\begin{Exercise}
\begin{enumerate}
\item Prove that the chromatic number of any graph $G$ is the maximum of the chromatic numbers of its
\begin{enumerate}[label = (\roman*)]
\item components.
\item blocks.
\end{enumerate}

\item Show that for any two graphs $G$ and $H$,
\begin{enumerate}[label = (\roman*)]
\item $\chi(G \cup H) = \max(\chi(G), \chi(H))$.
\item $\chi(G + H) = \chi(G) + \chi(H)$.
\end{enumerate}

\item Let $G = K_2 + C_5$. Compute $\omega(G)$ and $\chi(G)$.

\item Let $G = K_p + C_{2r + 1}$, where $r \ge 2$. Compute $\omega(G)$ and $\chi(G)$.

\item Suppose that $G$ is a graph such that $\chi(G) = \omega(G) + 1$. Recursively define $H_k$ as $H_1 = G$, $H_k = H_{k - 1} + G$, $k > 1$ (i.e. $H_k$ is the join of $k$ copies of $G$). Prove that $\chi(H_k) = \omega(H_k) + k$.
\end{enumerate}
\end{Exercise}

\subsection*{Chromatic polynomials}\label{subsec:ChromaticPolynomials}

For any non-negative integer $k$, we denote the number of proper $k$-colourings of the graph $G$ by $p_\chi(G; k)$. We shall see that $p_\chi(G; k)$ can be expressed as a polynomial in $k$.

\begin{Exercise}
By combinatorial arguments, prove the following:
\begin{enumerate}
\item $p_\chi(K_n; k) = k(k - 1) \cdots (k - n + 1)$.

\item $p_\chi(\overline{K_n}; k) = k^n$.

\item $p_\chi(P_n; k) = k(k - 1)^{n - 1}$.

\item $p_\chi(C_4; k) = k^4 - 4k^3 + 6k^2 - 4k + k = (k - 1)^4 + (k - 1)$. \hint{Use the principle of inclusion and exclusion.}
\end{enumerate}
\end{Exercise}

Consider a partition of $V(G)$ into independent sets. Then any assignment of colours from $\{1, \ldots, k\}$ to $G$ that assign distinct colours for vertices in different parts of the partition, such that all vertices in the same part receive the same colour, is a proper $k$-colouring of $G$. Conversely, any proper $k$-colouring of $G$ induces such a partition of $G$ into independent sets that are precisely the colour classes. If the number of parts in the partition is $r$, then the number of different such colourings possible is $k(k - 1) \cdots (k - r + 1)$. Thus, if $\pi_r(G)$ is the number of ways to partition $V(G)$ into $r$ independent sets, then

\begin{equation*}
p_\chi(G; k) = \sum_{r = 1}^{n} \pi_r(G) k(k - 1) \cdots (k - r + 1).
\end{equation*}

Note that this is a polynomial in $k$. If $n$ is the order of $G$, then $\pi_n(G) = 1$, which implies that $p_\chi(G; k)$ is a monic polynomial in $k$ having degree $n$.

The \newterm{chromatic polynomial} of $G$ with indeterminate $x$ is the unique monic polynomial in $x$ of degree $n$ whose value at $x = k$ is $p_\chi(G; k)$, for every non-negative integer $k$. We denote it by $p_\chi(G; x)$.

The \newterm{contraction} of an edge $e$ of $G$ is the operation of removing $e$ and replacing its end-vertices by a new single vertex that is incident with all the edges that are adjacent to $e$ in $G$. The resulting graph is denoted by $G \cdot e$. Now, we give a recurrence relation for computing the chromatic polynomial of $G$ in terms of edge contraction and edge deletion.

\begin{Theorem}\label{thm:ChromPolyRecurrence}
If $e$ is an edge of a graph $G$, then
\begin{equation*}
p_\chi(G; x) = p_\chi(G - e; x) - p_\chi(G \cdot e; x).
\end{equation*}
\end{Theorem}

\begin{proof}
Let $e = uv$. Any proper $k$-colouring of $G - e$ assigns either the same colour or two different colours to $u$ and $v$. Any colouring of the first kind defines a proper $k$-colouring of $G \cdot e$, where the new vertex of $G \cdot e$ receives the same colour as $u$ and $v$, and any vertex receives the same colours as in $G - e$. Any colouring of $G \cdot e$ of the second kind is naturally a proper $k$-colouring of $G$, as it assigns different colours to $u$ and $v$, the end-vertices of $e$. Thus, $p_\chi(G - e; x) = p_\chi(G \cdot e; x) + p_\chi(G; x)$.
\end{proof}

\begin{Theorem}[Whitney]
For any graph $G$ of order $n$, the chromatic polynomial $p_\chi(G; x)$ is a monic polynomial of degree $n$, with integer coefficients alternating in sign, having $-m$ as the coefficient of $x^{n - 1}$.
\end{Theorem}

\begin{proof}
Let $m$ be the size of $G$. We prove the result by induction on $m$. If $m = 0$, $G \cong \overline{K_n}$, and hence $p_\chi(G; x) = x^n$, so the result holds.

Assume, for the sake of induction, that the result holds for any graph of size $m - 1$ and let $G$ be a graph of order $n$ and size $m$, where $m \ge 1$. As $G - e$ and $G \cdot e$ are each of size $m - 1$, by the induction hypothesis,
\begin{align*}
p_\chi(G - e; x) 		& = x^n - (m - 1) x^{n - 1} + a_2 x^{n - 2} - \cdots + (-1)^r a_r x^{n - r} + \cdots \\
p_\chi(G \cdot e; x)	& = x^{n - 1} - (m - 1) x^{n - 2} + b_2 x^{n - 2} - \cdots + (-1)^r b_r x^{n - r} + \cdots \\
\end{align*}
for some non-negative integers $a_2, a_3, \ldots$ and $b_2, b_3, \ldots$.

Now, by \cref{thm:ChromPolyRecurrence}, the chromatic polynomial of $G$ is given by
\begin{align*}
p_\chi(G; x) & = x^n - [(m - 1) + 1] x^{n - 1} + (a_2 + m - 1) x^{n - 2} - {} \spliteq \splitalign \cdots + (-1)^r(a_r + b_r) x^{n - r} + \cdots \\
	& = x^n - m x^{n - 1} + (a_2 + m - 1) x^{n - 2} - \cdots + (-1)^r(a_r + b_r) x^{n - r} + \cdots
\end{align*}
which proves the result.
\end{proof}

\begin{Exercise}
Using \cref{thm:ChromPolyRecurrence}, prove by mathematical induction that
\begin{enumerate}
\item $p_\chi(C_n; x) = (x - 1)^n + (-1)^n (x - 1)$ for any $n \ge 3$.
\item $p_\chi(T; x) = x(x - 1)^{n - 1}$ for any tree $T$ of order $n$.
\end{enumerate}
\end{Exercise}